{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face Recognition V2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAPNO3q6SIXQ",
        "colab_type": "text"
      },
      "source": [
        "# Facenet repo\n",
        "\n",
        "\n",
        "```\n",
        "https://github.com/davidsandberg/facenet\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Insightface repo\n",
        "\n",
        "\n",
        "```\n",
        "https://github.com/deepinsight/insightface.git\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EdaaJE4MbJ2s"
      },
      "source": [
        "# Google Drive Directory\n",
        "\n",
        "\n",
        "```\n",
        "https://drive.google.com/drive/folders/1vqKryG2EC2PyHxdvjzEyou6eaqIZu5Rq?usp=sharing\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQnpqgOHM54v",
        "colab_type": "text"
      },
      "source": [
        "# Preparing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iH-HLuPqQxnu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cloning facenet repo\n",
        "!git clone https://github.com/davidsandberg/facenet\n",
        "\n",
        "# downloading VGGFace2 pretrained model\n",
        "# https://drive.google.com/file/d/1EXPBSXwTaqrSC0OhUdXNmKSh9qJUQ55-/view\n",
        "!cp '/content/drive/My Drive/Motion Capture project ITI intake40/scripts/Facenet/20180402-114759.zip' /content/\n",
        "\n",
        "#unpacking the model\n",
        "!mkdir /content/facenet/model/\n",
        "!unzip /content/20180402-114759.zip -d /content/facenet/model/\n",
        "\n",
        "#clean up\n",
        "!rm /content/20180402-114759.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlG60El5QEb8",
        "colab_type": "text"
      },
      "source": [
        "# **Face Detection & Alignment**\n",
        "  using insightface mxnet model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FBvxIiNQjjJ",
        "colab_type": "text"
      },
      "source": [
        "Prepare needed files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiOxYR0JQJdr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cloning insightface repo\n",
        "!pip install mxnet-cu100\n",
        "!git clone --recursive https://github.com/deepinsight/insightface.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24ilv-PYQugo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# downloading pretrained detection model\n",
        "!wget https://www.dropbox.com/s/53ftnlarhyrpkg2/retinaface-R50.zip\n",
        "\n",
        "# unpacking the model\n",
        "!unzip /content/retinaface-R50.zip -d /content/insightface/models/\n",
        "\n",
        "# unpacking cython files\n",
        "!cd /content/insightface/RetinaFace/rcnn/cython ;  python setup.py build_ext --inplace"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMjW9NiqXVJr",
        "colab_type": "text"
      },
      "source": [
        "loading data and needed scripts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7HcIDw0XbmW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#copying our test data from drive\n",
        "!cp -r /content/drive/My\\ Drive/Motion\\ Capture\\ project\\ ITI\\ intake40/Data/Faces\\ images/unprocessed /content/data\n",
        "\n",
        "#load modified scripts\n",
        "!cp '/content/drive/My Drive/Motion Capture project ITI intake40/scripts/Facenet/align_dataset_mtcnn.py' /content/facenet/src/align/ "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJUfwz90XcUG",
        "colab_type": "text"
      },
      "source": [
        "Execute script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkULDj-eXeSe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python /content/facenet/src/align/align_dataset_mtcnn.py --image_size 160 --margin 20 --detect_multiple_faces True /content/data/ /content/aligned/\n",
        "# input dir /content/data/    output dir /content/aligned/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3UFzE-4bi1G",
        "colab_type": "text"
      },
      "source": [
        "save new data and scripts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ru_pQpb6brx-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/facenet/src/align/align_dataset_mtcnn.py '/content/drive/My Drive/Motion Capture project ITI intake40/scripts/Facenet/'\n",
        "\n",
        "# copy aligned folder to drive to manually clean\n",
        "!cp -r /content/aligned/  '/content/drive/My Drive/Motion Capture project ITI intake40/Data/Faces images/processed'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yw81F5-aeUEs",
        "colab_type": "text"
      },
      "source": [
        "# **Data augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_cNGFr43QyV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#copying our test data from drive\n",
        "!cp -r /content/drive/My\\ Drive/Motion\\ Capture\\ project\\ ITI\\ intake40/Data/Faces\\ images/processed /content/data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kB-0zl1oehpD",
        "colab_type": "code",
        "outputId": "90361e71-7de3-46b5-a504-2cdb0c9edbb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!pip install -U git+https://github.com/albu/albumentations > /dev/null && echo \"All libraries are successfully installed!\"\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython.display import display, HTML \n",
        "\n",
        "from albumentations import (VerticalFlip, HorizontalFlip, Flip, RandomRotate90, Rotate, ShiftScaleRotate, CenterCrop, OpticalDistortion, GridDistortion, ElasticTransform, JpegCompression, HueSaturationValue,\n",
        "                            RGBShift, RandomBrightness, RandomContrast, Blur, MotionBlur, MedianBlur, GaussNoise, CLAHE, ChannelShuffle, InvertImg, RandomGamma, ToGray, PadIfNeeded \n",
        "                           )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Running command git clone -q https://github.com/albu/albumentations /tmp/pip-req-build-1jy3fli2\n",
            "All libraries are successfully installed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyOKwJSye2vX",
        "colab_type": "text"
      },
      "source": [
        "helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9R7ABfoe4pL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_img(img, figsize=(8, 8)):\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "    ax.grid(False)\n",
        "    ax.set_yticklabels([])\n",
        "    ax.set_xticklabels([])\n",
        "    ax.imshow(img)\n",
        "    plt.imshow(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haU1YP7zr7pe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Enter input data directory { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "from PIL import Image\n",
        "import random\n",
        "import os\n",
        "\n",
        "# load a random image to show augmentation effects\n",
        "def load_image(dir_path):\n",
        "    path_exp = os.path.expanduser(dir_path)\n",
        "    paths = [path for path in os.listdir(path_exp) if os.path.isdir(os.path.join(path_exp, path))]\n",
        "    count = 0\n",
        "    while True:\n",
        "      if count == 10:\n",
        "        return None\n",
        "      file_name = \"\"\n",
        "      try:\n",
        "        directory = random.choice(paths)\n",
        "        file_name = random.choice(os.listdir(dir_path + directory))\n",
        "        img = Image.open(dir_path + directory +'/'+ file_name)\n",
        "        return dir_path + directory +'/'+ file_name\n",
        "      except:\n",
        "        count = count + 1\n",
        "        print('NOT IMAGE: ', dir_path + directory +'/'+ file_name)\n",
        "        continue\n",
        "\n",
        "data_path =  '/content/data/aligned/' #@param {type:\"string\"}\n",
        "path = load_image(data_path)\n",
        "print('test image: ', path)\n",
        "if path != None:\n",
        "  show_img(Image.open(path))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W14YyEkpfxwQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Choose required augmentations { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "def augment_image(img_path, show_output=True):\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    if len(img) > 0:\n",
        "        angle = 96 #@param {type:\"slider\", min:0, max:360, step:1}\n",
        "        shift = 0 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "        scale = 1 #@param {type:\"slider\", min:0, max:2, step:0.1}\n",
        "\n",
        "        aug = ShiftScaleRotate(p=0.5)\n",
        "        img = aug.apply(img, angle=angle, scale=scale, dx=shift, dy=shift)\n",
        "\n",
        "        flip_image = \"Disabled\" #@param [\"Vertical\", \"Horizontal\", \"Both Horizontal and Vertical\", \"Disabled\"]\n",
        "        state_to_code = {\n",
        "            \"Both Horizontal and Vertical\": -1,\n",
        "            \"Vertical\": 0,\n",
        "            \"Horizontal\": 1,\n",
        "        }\n",
        "        aug = Flip(p=0.5)\n",
        "        if flip_image == \"Disabled\":\n",
        "          pass\n",
        "        else:\n",
        "          img = aug.apply(img, d=state_to_code[state]) \n",
        "        #@markdown ---\n",
        "        Brightness = False #@param {type:\"boolean\"}\n",
        "        if Brightness:\n",
        "            alpha = 0.6 #@param {type:\"slider\", min:0, max:5, step:0.1}\n",
        "            aug = RandomBrightness(p=0.5)\n",
        "            img = aug.apply(img, alpha=alpha)\n",
        "\n",
        "        Contrast = False #@param {type:\"boolean\"}\n",
        "        if Contrast:\n",
        "          alpha = 0.9 #@param {type:\"slider\", min:0, max:3, step:0.1}\n",
        "          aug = RandomContrast(p=0.5)\n",
        "          img = aug.apply(img, alpha=alpha)\n",
        "        #@markdown ---\n",
        "        RGB_Shift = False #@param {type:\"boolean\"}\n",
        "        if RGB_Shift:\n",
        "          r_shift = 0 #@param {type:\"slider\", min:-255, max:255, step:1}\n",
        "          g_shift = 45 #@param {type:\"slider\", min:-255, max:255, step:1}\n",
        "          b_shift = 40 #@param {type:\"slider\", min:-255, max:255, step:1}\n",
        "\n",
        "          aug = RGBShift(p=0.5)\n",
        "          img = aug.apply(img, r_shift=r_shift, g_shift=g_shift, b_shift=b_shift)\n",
        "\n",
        "        hue_saturation = False #@param {type:\"boolean\"}\n",
        "        if hue_saturation:\n",
        "          hue_shift = 122 #@param {type:\"slider\", min:0, max:180, step:1}\n",
        "          sat_shift = 97 #@param {type:\"slider\", min:0, max:255, step:1}\n",
        "          val_shift = 45 #@param {type:\"slider\", min:0, max:255, step:1}\n",
        "\n",
        "          aug = HueSaturationValue(p=0.5)\n",
        "          img = aug.apply(img, hue_shift=hue_shift, sat_shift=sat_shift, val_shift=val_shift)\n",
        "\n",
        "        gamma = False #@param {type:\"boolean\"}\n",
        "        if gamma:\n",
        "          gamma = 37 #@param {type:\"slider\", min:0, max:255, step:1}\n",
        "          aug = RandomGamma(p=0.5)\n",
        "          img = aug.apply(img, gamma=gamma / 100)\n",
        "\n",
        "        #@markdown ---\n",
        "        Elastic_transform = False #@param {type:\"boolean\"}\n",
        "        if Elastic_transform:\n",
        "          alpha = 203 #@param {type:\"slider\", min:0, max:255, step:1}\n",
        "          alpha_affine = 106 #@param {type:\"slider\", min:0, max:255, step:1}\n",
        "          sigma = 166 #@param {type:\"slider\", min:0, max:255, step:1}\n",
        "          aug = ElasticTransform(p=0.5)\n",
        "          img = aug.apply(img, alpha=alpha, sigma=sigma, alpha_affine=alpha_affine)\n",
        "        \n",
        "        #@markdown ---\n",
        "        Optical_Distortion = False #@param {type:\"boolean\"}\n",
        "        if Optical_Distortion:\n",
        "          distort_limit = 0.4 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "          shift_limit = 0.15 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "          aug = OpticalDistortion(p=0.5)\n",
        "          img = aug.apply(img, k=distort_limit, dx=shift_limit, dy=shift_limit)\n",
        "        \n",
        "        #@markdown ---\n",
        "        Center_crop = False #@param {type:\"boolean\"}\n",
        "        if Center_crop:\n",
        "          size = 288 #@param {type:\"slider\", min:32, max:512, step:16}\n",
        "          aug = CenterCrop(height=size, width=size, p=0.5)\n",
        "          img = aug.apply(img)\n",
        "        \n",
        "        #@markdown ---\n",
        "        jpeg_compression = False #@param {type:\"boolean\"}\n",
        "        if jpeg_compression:\n",
        "          quality = 23 #@param {type:\"slider\", min:0, max:100, step:1}\n",
        "          aug = JpegCompression(p=1)\n",
        "          img = aug.apply(img, quality=quality)\n",
        "\n",
        "        if show_output:\n",
        "          show_img(img)\n",
        "        return img\n",
        "\n",
        "ret = augment_image(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19Uyak0n7z6G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# apply to all images\n",
        "output_directory = '/content/augmented/'\n",
        "path_exp = os.path.expanduser(data_path)\n",
        "paths = [path for path in os.listdir(path_exp) if os.path.isdir(os.path.join(path_exp, path))]\n",
        "for directory in paths:\n",
        "    for file in os.listdir(path_exp + directory):\n",
        "        if os.path.isdir(path_exp + directory + '/' + file):\n",
        "          paths.append(path_exp + directory + '/' + file)\n",
        "        else:\n",
        "          ret = augment_image(path_exp + directory + '/' + file, show_output=False)\n",
        "          if not os.path.exists(output_directory + directory):\n",
        "              os.makedirs(output_directory + directory)\n",
        "          cv2.imwrite(output_directory + directory + '/' + file, ret)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tCb_QB_Tc1s",
        "colab_type": "text"
      },
      "source": [
        "# **Face Recognition**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SV1xQTZOTm46",
        "colab_type": "text"
      },
      "source": [
        "Preparing test specific data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E78gTD02Tl5F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#copying our test data from drive\n",
        "!cp -r /content/drive/My\\ Drive/Motion\\ Capture\\ project\\ ITI\\ intake40/Data/Faces\\ images/processed /content/data\n",
        "\n",
        "#load modified scripts\n",
        "!cp '/content/drive/My Drive/Motion Capture project ITI intake40/scripts/Facenet/classifier.py' /content/facenet/src/ \n",
        "!cp '/content/drive/My Drive/Motion Capture project ITI intake40/scripts/Facenet/facenet.py' /content/facenet/src/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMcO77kJV6m_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#running test script\n",
        "!python /content/facenet/src/classifier.py /content/data/aligned/ /content/facenet/model/20180402-114759/ /content/aligned/zeinab/10626407_1039483162746713_2617121640081663520_o_2.png\n",
        "# data_dir '/content/data/train/' model '/content/facenet/model/20180402-114759/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DKDQ35UXfjI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img = Image.open('/content/aligned/zeinab/10626407_1039483162746713_2617121640081663520_o_2.png')\n",
        "plt.imshow(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utl5Zj35d3Gp",
        "colab_type": "text"
      },
      "source": [
        "Save modified scripts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbR7Sc71d7qv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/facenet/src/classifier.py '/content/drive/My Drive/Motion Capture project ITI intake40/scripts/Facenet/'\n",
        "!cp /content/facenet/src/facenet.py  '/content/drive/My Drive/Motion Capture project ITI intake40/scripts/Facenet/'"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}